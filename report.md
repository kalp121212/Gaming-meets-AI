# Gaming Meets AI- SoC Project Report

## Task 1:

- **Python**:- I already knew basics of python before joining this SoC, so i did a quick revision on my python using the resources provided and we were also given a python assignment with questions related to numpy library.

- **Introduction to ML**:- I had already done a very basic ML course by AndrewNg before joining this SoC so when we were provided provided resource links for learning the basics of ML, DL and RL from CS229 stanford lectures, it was a good quick revision for ML concepts as well as getting to know new concepts about RL.

### Resource links:

- [Python Tutorial Website](learnpython.org)
- [CS229 Stanford Lecture Videos](https://www.youtube.com/watch?v=jGwO_UgTS7I&list=PLoROMvodv4rMiGQp3WXShtMGgzqpfVfbU)

## Task 2:

- **Probability and Linear Algebra**:- We were provided a book on DL and first thing we had to learn were the basis probability distributions such as Bernoulli, Multinoulli and Gaussian distributions. In addition to this few advances topics in Linear Algebra were also covered which was good since we had a Linear Algebra course (MA106) going on simultaneously which helped me understand the concepts in a better way.
- **Machine learning basics**:- Next, we had to read about basics of ML with supervised and unsupervised algorithms as well as studied other things realted to ML like over-fitting, under-fitting, hyperparamters and validation sets. This was also a good revision from the AndrewNg course which i had done before.
- **Deep Learning and Neural Networks**:- This was one concept i still havnt grasped properly, went through the books and learnt basics about Perceptrons, sigmoid neurons,activation functions, MLPs, back-propagation algorithm but i am still not confident enough with this topic.

### Resource links-
- [Basic ML and DL course by AndrewNg on coursera](https://www.coursera.org/learn/machine-learning)
- [Book provided for DL](http://faculty.neu.edu.cn/yury/AAI/Textbook/DeepLearningBook.pdf)
- [3b1b Video for Neural Networks](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)

## Task 3:

- **Introduction to Reinforment Learning**:- We were provided a book on RL and the first few chapters were about what RL is and why is it used and its various kinds of methods and important theory about exploration vs exploitation and usage of greedy and epsilon greedy methods and also important terms related to RL such as MDP, value functions, policies etc.

- **Methods to implement RL**:- Here we learnt about algorithms to implement RL in real world problems. First we learnt about DP(dynamic programming) methods to implement value iteration and policy iteration algorithms, i went through a couple of YouTube videos to get a better understanding of how these algorithms work, next we learnt about Monte Carlo methods using exploring stats and without exploring stats, i am not very confident with this algorithm yet.

### Resource links-
- [RL book by Richard S. Sutton and Andrew G. Barto](https://web.stanford.edu/class/psych209/Readings/SuttonBartoIPRLBook2ndEd.pdf)
- [Stanford lectures for RL](https://www.youtube.com/watch?v=FgzM3zpZ55o&list=PLoROMvodv4rOSOPzutgyCTapiGlY2Nd8u)

## Task 4: Coding the project

- **Tensorflow and Pytorch**:- Now we were given tutorials on PyTorch and TensorFlow to understand how a neural network is coded in practice. This helped in understanding how exactly the code should be structured.

- **Final coding**:- This was the main coding period where we were expected to implement all the theory learnt into practice. First, I made a simple general DQN network to train network for the cartpole problem on OpenAI Gym. This was very helpful to learn the basic way of how the code worked. Later, I extended this implementation to work for 2048 game and then trained its performance for 2048 too.

### Resource links-
- [PyTorch tutorials](https://pytorch.org/tutorials/)
- [TensorFlow tutorials](https://www.tensorflow.org/tutorials)
